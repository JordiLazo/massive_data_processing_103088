{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Built-in Data Sources\n",
        "\n"
      ],
      "metadata": {
        "id": "OIDPhiigMKQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the environment\n",
        "First, we are going to prepare the environment for running PySaprk in the Google Collab Machine (if you work directly in your computer, and you want to prepare it, read and follow champter 2 instructions)"
      ],
      "metadata": {
        "id": "bgS3nhjaMQQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTEPUoaL69gw",
        "outputId": "2edc44b2-193e-4417-b588-094a83f751b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/UDL/install_pyspark.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsdkaEd97EHI",
        "outputId": "dba51187-20cc-4cb8-e31e-7673024836a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Install JAVA 8\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=c9ef5ccadab0e2a7cc62612861b2fd3e98000b0f82ffb72426989aa4b3fb1cb6\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Obtaining last version of spark\n",
            "/content/drive/MyDrive/UDL/install_pyspark.py:17: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 17 of the file /content/drive/MyDrive/UDL/install_pyspark.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  soup = BeautifulSoup(html_doc)\n",
            "Getting version spark-3.2.1\n",
            "Downloading https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
            "Installing PySpark\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 281.4 MB 30 kB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 198 kB 57.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Setting environment variables for JAVA_HOME and SPARK_HOME\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start working with Spark\n",
        "Now we now and understand how Spark appeared in our lives and more or less how it works (and you know, it's amazing ðŸ¤­), we can start to work with it.\n",
        "As you now, the SparkSession is the way programmers \"talk\" with Spark. So, we need to inicialize that.\n",
        "TAKE INTO ACCOUNT, this time, qwe are using, also, \"enableHiveSupport\". This is beacouse we are going to create databases in SparkSQL and it's needed."
      ],
      "metadata": {
        "id": "u3_oicKBMsEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = (SparkSession\n",
        " .builder\n",
        " .appName(\"example\")\n",
        " .enableHiveSupport()\n",
        " .getOrCreate())"
      ],
      "metadata": {
        "id": "ekZc-YctYpwJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data from CSV\n",
        "Download data from https://raw.githubusercontent.com/databricks/LearningSparkV2/master/databricks-datasets/learning-spark-v2/flights/departuredelays.csv"
      ],
      "metadata": {
        "id": "z095l-qbWL2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "# Path to data set\n",
        "csv_url = \"https://raw.githubusercontent.com/databricks/LearningSparkV2/master/databricks-datasets/learning-spark-v2/flights/departuredelays.csv\"\n",
        "wget.download(csv_url)\n",
        "# Read and create a temporary view\n",
        "# Infer schema (note that for larger files you\n",
        "# may want to specify the schema)\n",
        "schema = \"`date` STRING, `delay` INT, `distance` INT, `origin` STRING, `destination` STRING\"\n",
        "\n",
        "df = (spark.read.format(\"csv\")\n",
        " .option(\"inferSchema\", \"true\")\n",
        " .option(\"header\", \"true\")\n",
        " .schema(schema)\n",
        " .load(\"departuredelays.csv\"))\n",
        "df.createOrReplaceTempView(\"us_delay_flights_tbl\")\n"
      ],
      "metadata": {
        "id": "aw7yuLR2WEwj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "id": "fuoB82W1Wiir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7780055b-9581-4586-f5a6-ad33e5c676c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+--------+------+-----------+\n",
            "|    date|delay|distance|origin|destination|\n",
            "+--------+-----+--------+------+-----------+\n",
            "|01011245|    6|     602|   ABE|        ATL|\n",
            "|01020600|   -8|     369|   ABE|        DTW|\n",
            "|01021245|   -2|     602|   ABE|        ATL|\n",
            "|01020605|   -4|     602|   ABE|        ATL|\n",
            "|01031245|   -4|     602|   ABE|        ATL|\n",
            "|01030605|    0|     602|   ABE|        ATL|\n",
            "|01041243|   10|     602|   ABE|        ATL|\n",
            "|01040605|   28|     602|   ABE|        ATL|\n",
            "|01051245|   88|     602|   ABE|        ATL|\n",
            "|01050605|    9|     602|   ABE|        ATL|\n",
            "|01061215|   -6|     602|   ABE|        ATL|\n",
            "|01061725|   69|     602|   ABE|        ATL|\n",
            "|01061230|    0|     369|   ABE|        DTW|\n",
            "|01060625|   -3|     602|   ABE|        ATL|\n",
            "|01070600|    0|     369|   ABE|        DTW|\n",
            "|01071725|    0|     602|   ABE|        ATL|\n",
            "|01071230|    0|     369|   ABE|        DTW|\n",
            "|01070625|    0|     602|   ABE|        ATL|\n",
            "|01071219|    0|     569|   ABE|        ORD|\n",
            "|01080600|    0|     369|   ABE|        DTW|\n",
            "+--------+-----+--------+------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "W2aydYIPx2XI",
        "outputId": "0775bfec-2918-4f03-f9e5-80d9e9557725"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[date: string, delay: int, distance: int, origin: string, destination: string]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using SPARK SQL"
      ],
      "metadata": {
        "id": "ZjDPWgeGgLIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter flights whose distance is > 1000 miles"
      ],
      "metadata": {
        "id": "bX3ZCY71gVyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " ### Filter flights whose distance is > 1000 miles"
      ],
      "metadata": {
        "id": "Cqq1NZx7gKhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT distinct DISTANCE , ORIGIN, DESTINATION\n",
        "  FROM  us_delay_flights_tbl \n",
        "  WHERE DISTANCE > 1000\n",
        "  ORDER BY distance DESC  \n",
        "  \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBAnj-NCgUmG",
        "outputId": "1e3f0d3b-0b73-48c7-f504-aa37133c4b97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+-----------+\n",
            "|DISTANCE|ORIGIN|DESTINATION|\n",
            "+--------+------+-----------+\n",
            "|    4330|   JFK|        HNL|\n",
            "|    4330|   HNL|        JFK|\n",
            "|    4312|   HNL|        EWR|\n",
            "|    4312|   EWR|        HNL|\n",
            "|    4186|   HNL|        IAD|\n",
            "|    4186|   IAD|        HNL|\n",
            "|    3912|   ATL|        HNL|\n",
            "|    3912|   HNL|        ATL|\n",
            "|    3687|   HNL|        ORD|\n",
            "|    3687|   ORD|        HNL|\n",
            "|    3392|   HNL|        IAH|\n",
            "|    3392|   IAH|        HNL|\n",
            "|    3303|   GUM|        HNL|\n",
            "|    3303|   HNL|        GUM|\n",
            "|    3288|   HNL|        DFW|\n",
            "|    3288|   DFW|        HNL|\n",
            "|    3224|   DFW|        OGG|\n",
            "|    3224|   OGG|        DFW|\n",
            "|    2967|   LIH|        DEN|\n",
            "|    2967|   DEN|        LIH|\n",
            "+--------+------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter flights whose distance is > 1000 miles"
      ],
      "metadata": {
        "id": "J6Q1mkF4CS7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "  SELECT date, delay, origin, destination\n",
        "  FROM  us_delay_flights_tbl \n",
        "  WHERE delay > 120 and ORIGIN = 'SFO' \n",
        "  AND destination = 'ORD'\n",
        "  ORDER BY delay DESC  \n",
        "  \"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBhjQl96BeCv",
        "outputId": "74027a9c-94ff-48d4-bcf6-c6b520598940"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+------+-----------+\n",
            "|    date|delay|origin|destination|\n",
            "+--------+-----+------+-----------+\n",
            "|02190925| 1638|   SFO|        ORD|\n",
            "|01031755|  396|   SFO|        ORD|\n",
            "|01022330|  326|   SFO|        ORD|\n",
            "|01051205|  320|   SFO|        ORD|\n",
            "|01190925|  297|   SFO|        ORD|\n",
            "|02171115|  296|   SFO|        ORD|\n",
            "|01071040|  279|   SFO|        ORD|\n",
            "|01051550|  274|   SFO|        ORD|\n",
            "|03120730|  266|   SFO|        ORD|\n",
            "|01261104|  258|   SFO|        ORD|\n",
            "|01161210|  225|   SFO|        ORD|\n",
            "|02091800|  223|   SFO|        ORD|\n",
            "|01221040|  215|   SFO|        ORD|\n",
            "|03121155|  203|   SFO|        ORD|\n",
            "|02111256|  197|   SFO|        ORD|\n",
            "|03311405|  196|   SFO|        ORD|\n",
            "|01031920|  193|   SFO|        ORD|\n",
            "|01021410|  190|   SFO|        ORD|\n",
            "|03171215|  189|   SFO|        ORD|\n",
            "|03260828|  184|   SFO|        ORD|\n",
            "+--------+-----+------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Exercise 1: \n",
        "\n",
        "\n",
        "*   Convert the DATE column into readable format\n",
        "*   Find the days or months when these delays were most common\n",
        "*   Try to answer with your data results: Were the delays related to winters months or holidays?"
      ],
      "metadata": {
        "id": "MOsxlkTMCVkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pass"
      ],
      "metadata": {
        "id": "yvDksKT9CEB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Case clause in Spark SQL\n",
        "In this query, we are trying to label all US flights, regardless of origin and destination, with an indication of the delays they experienced:\n",
        "\n",
        "\n",
        "*   Very Long Delays (> 6 hours)\n",
        "*   Long Delays (2-6 hours)\n",
        "*   Short Delays (1-2 hours)\n",
        "*   Tolerable delay (< 1 hour)\n",
        "We'll add these labels in a new column called: *Flight_Delays*\n"
      ],
      "metadata": {
        "id": "JO4O6nH5C9up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "SELECT delay, origin, destination, \n",
        "  CASE\n",
        "    WHEN delay > 360 THEN 'Very Long Delay'\n",
        "    WHEN delay > 120 AND delay <= 360 THEN 'Long Delay'\n",
        "    WHEN delay > 60 AND delay <= 120 THEN 'Short Delay'\n",
        "    WHEN delay > 0 AND delay <= 60 THEN 'Tolenable Delay'\n",
        "    WHEN delay = 0 THEN 'No Delay'\n",
        "    ELSE 'Early'\n",
        "  END AS Flight_Delays\n",
        "FROM us_delay_flights_tbl\n",
        "ORDER BY origin, delay DESC\n",
        "\"\"\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Aakxnc1C9L1",
        "outputId": "25ce2fd5-3238-4ac0-ea48-e82abee8f7fc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+-----------+-------------+\n",
            "|delay|origin|destination|Flight_Delays|\n",
            "+-----+------+-----------+-------------+\n",
            "|  333|   ABE|        ATL|   Long Delay|\n",
            "|  305|   ABE|        ATL|   Long Delay|\n",
            "|  275|   ABE|        ATL|   Long Delay|\n",
            "|  257|   ABE|        ATL|   Long Delay|\n",
            "|  247|   ABE|        DTW|   Long Delay|\n",
            "|  247|   ABE|        ATL|   Long Delay|\n",
            "|  219|   ABE|        ORD|   Long Delay|\n",
            "|  211|   ABE|        ATL|   Long Delay|\n",
            "|  197|   ABE|        DTW|   Long Delay|\n",
            "|  192|   ABE|        ORD|   Long Delay|\n",
            "|  180|   ABE|        ATL|   Long Delay|\n",
            "|  173|   ABE|        DTW|   Long Delay|\n",
            "|  165|   ABE|        ATL|   Long Delay|\n",
            "|  159|   ABE|        ATL|   Long Delay|\n",
            "|  159|   ABE|        ORD|   Long Delay|\n",
            "|  158|   ABE|        ATL|   Long Delay|\n",
            "|  151|   ABE|        DTW|   Long Delay|\n",
            "|  127|   ABE|        ATL|   Long Delay|\n",
            "|  121|   ABE|        DTW|   Long Delay|\n",
            "|  118|   ABE|        DTW|  Short Delay|\n",
            "+-----+------+-----------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resturn to slides"
      ],
      "metadata": {
        "id": "WGG3GAkuKPM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating SQL Databases and Tables "
      ],
      "metadata": {
        "id": "sOKyTqpaKSEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"CREATE DATABASE learn_spark_db\")\n",
        "spark.sql(\"USE learn_spark_db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nouzWNHnEyVW",
        "outputId": "b66fbc9c-2aab-4464-b061-8e06fa171d0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating MANAGED data table"
      ],
      "metadata": {
        "id": "zMuGKS5fQyaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "CREATE TABLE managed_us_delay_flights_tbl \n",
        "  (date STRING, delay INT, distance INT, origin STRING, destination STRING)\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJz_N6TNKpyH",
        "outputId": "73ca8601-3476-4ddd-d33f-eff5651c34d7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a UNMANAGED data table:\n"
      ],
      "metadata": {
        "id": "T-tbPD00Q0sQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"\n",
        "CREATE TABLE unmanaged_us_delay_flights_tbl \n",
        "  (date STRING, delay INT, distance INT, origin STRING, destination STRING)\n",
        "  USING csv OPTIONS (PATH 'mydeparturesdelays.csv')\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mh33-IYK0nu",
        "outputId": "62282e78-6262-45f7-9060-42353f363725"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a view"
      ],
      "metadata": {
        "id": "FUBT8HbNSwm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sfo = spark.sql(\"SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'SFO'\")\n",
        "df_jfk = spark.sql(\"SELECT date, delay, origin, destination FROM us_delay_flights_tbl WHERE origin = 'JFK'\")\n",
        "df_sfo.createOrReplaceGlobalTempView(\"us_origin_airport_SFO_global_tmp_view\")\n",
        "df_jfk.createOrReplaceTempView(\"us_origin_airport_JFK_tmp_view\")\n"
      ],
      "metadata": {
        "id": "seXM0foaRDSi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting from a view (when we do a select into a table, the result is a DF):"
      ],
      "metadata": {
        "id": "EVDfiGZDSyu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"SELECT * FROM us_origin_airport_JFK_tmp_view\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ9VCW_8SbK5",
        "outputId": "6e95776f-bef4-439e-fa9b-48c929457482"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[date: string, delay: int, origin: string, destination: string]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting the view:"
      ],
      "metadata": {
        "id": "6o2-olYKS5hH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.dropGlobalTempView(\"us_origin_airport_SFO_global_tmp_view\")\n",
        "spark.catalog.dropTempView(\"us_origin_airport_JFK_tmp_view\")\n"
      ],
      "metadata": {
        "id": "snHwPWGvS0bh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing the metadata"
      ],
      "metadata": {
        "id": "uW5SYeN7U33d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.listDatabases()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5ktn7TsS7UK",
        "outputId": "91bcf282-1f17-4c3a-ac24-254ae80eb43c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Database(name='default', description='Default Hive database', locationUri='file:/content/spark-warehouse'),\n",
              " Database(name='learn_spark_db', description='', locationUri='file:/content/spark-warehouse/learn_spark_db.db')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.listTables()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_Uc9jyuU-63",
        "outputId": "3b2710e7-8997-4d89-baae-33dc2fd3247c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Table(name='managed_us_delay_flights_tbl', database='learn_spark_db', description=None, tableType='MANAGED', isTemporary=False),\n",
              " Table(name='unmanaged_us_delay_flights_tbl', database='learn_spark_db', description=None, tableType='EXTERNAL', isTemporary=False),\n",
              " Table(name='us_delay_flights_tbl', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.catalog.listColumns(\"managed_us_delay_flights_tbl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBnfQO-HVCAn",
        "outputId": "4804808f-3ebe-4ab8-c809-3d9c5e891b81"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Column(name='date', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
              " Column(name='delay', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
              " Column(name='distance', description=None, dataType='int', nullable=True, isPartition=False, isBucket=False),\n",
              " Column(name='origin', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False),\n",
              " Column(name='destination', description=None, dataType='string', nullable=True, isPartition=False, isBucket=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KMxXcMn_VJOP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}